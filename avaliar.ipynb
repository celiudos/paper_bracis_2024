{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar um Dataset Anotado Sintético com dados para avaliar LGPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./output/dataset_sintetico_0_50.csv\")\n",
    "print(\"Qnt: \", len(df))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DADOS_FAKE = df.to_dict(orient=\"records\")\n",
    "DADOS_FAKE[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para converter em Tokens e Input IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "LABELS = [\n",
    "    \"O\",\n",
    "    \"B-NOME\",\n",
    "    \"I-NOME\",\n",
    "    \"B-DATA\",\n",
    "    \"I-DATA\",\n",
    "    \"B-ENDERECO\",\n",
    "    \"I-ENDERECO\",\n",
    "    \"B-CPF\",\n",
    "    \"I-CPF\",\n",
    "    \"B-TELEFONE\",\n",
    "    \"I-TELEFONE\",\n",
    "    \"B-EMAIL\",\n",
    "    \"I-EMAIL\",\n",
    "    \"B-DINHEIRO\",\n",
    "    \"I-DINHEIRO\",\n",
    "    \"B-CEP\",\n",
    "    \"I-CEP\",\n",
    "]\n",
    "\n",
    "\n",
    "def split_text_like_conll(text):\n",
    "    # A expressão regular. Separe também e deixe junto símbolos como R$\n",
    "    pattern = r\"\\w+|[^\\w\\s]|[0-9]+[.,][0-9]+\"\n",
    "    words_split = re.findall(pattern, text)\n",
    "    return words_split\n",
    "\n",
    "\n",
    "def convert_words_to_labels_ids(sentence=\"\", labels=LABELS, dados={}):\n",
    "    words = split_text_like_conll(sentence)\n",
    "    labels_ids = [0] * len(words)\n",
    "\n",
    "    for label_type, entries in dados.items():\n",
    "        b_label = \"B-\" + label_type\n",
    "        i_label = \"I-\" + label_type\n",
    "\n",
    "        for entry in entries:\n",
    "            entry_parts = split_text_like_conll(entry)\n",
    "            for start_index in range(len(words) - len(entry_parts) + 1):\n",
    "                if words[start_index : start_index + len(entry_parts)] == entry_parts:\n",
    "                    if b_label in labels:\n",
    "                        labels_ids[start_index] = labels.index(b_label)\n",
    "                        for j in range(1, len(entry_parts)):\n",
    "                            if i_label in labels:\n",
    "                                labels_ids[start_index + j] = labels.index(i_label)\n",
    "\n",
    "    return words, labels_ids\n",
    "\n",
    "\n",
    "# ===========\n",
    "\n",
    "TEXT_LOADED = \"Marinalva Bete Raz e Jorge Luiz receberam R$ 3.829,83 reais.\"\n",
    "DADOS_LOADED = {\n",
    "    \"NOME\": [\"Marinalva Bete Raz\", \"Jorge Luiz\"],\n",
    "    \"DINHEIRO\": [\"R$ 3.829,83\"],\n",
    "}\n",
    "\n",
    "output_words, output_labels = convert_words_to_labels_ids(\n",
    "    TEXT_LOADED, dados=DADOS_LOADED\n",
    ")\n",
    "print(output_words)\n",
    "print(output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Modelo atual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_transformer():\n",
    "    model_name = \"pierreguillou/ner-bert-large-cased-pt-lenerbr\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        max_length=512,\n",
    "        model_max_length=512,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return pipeline(\n",
    "        \"ner\",\n",
    "        tokenizer=tokenizer,\n",
    "        model=model_name,\n",
    "        aggregation_strategy=\"first\",\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "    )\n",
    "\n",
    "\n",
    "TRANSFORMER_MODEL = get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ModeloNerUtils import (\n",
    "    ModeloNerUtils,\n",
    ")\n",
    "\n",
    "ModeloNerUtilsObj = ModeloNerUtils(transformer=TRANSFORMER_MODEL)\n",
    "\n",
    "\n",
    "def model_fun(text):\n",
    "    PARAM = {\n",
    "        \"remover_labels\": [\n",
    "            \"LEGISLACAO\",\n",
    "            \"ORGANIZACAO\",\n",
    "            \"NUMERO\",\n",
    "            \"JURISPRUDENCIA\",\n",
    "            \"CNPJ\",\n",
    "        ],\n",
    "        \"merges\": {\n",
    "            \"NOME\": [\"PESSOA\"],\n",
    "            \"DATA\": [\"TEMPO\"],\n",
    "            \"ENDERECO\": [\"LOCAL\"],\n",
    "            \"CPF\": [\"CPF\"],\n",
    "            \"TELEFONE\": [\"TELEFONE\"],\n",
    "            \"EMAIL\": [\"EMAIL\"],\n",
    "            \"DINHEIRO\": [\"DINHEIRO\"],\n",
    "            \"CEP\": [\"CEP\"],\n",
    "        },\n",
    "    }\n",
    "    ents = ModeloNerUtilsObj.merge_all_models(text)\n",
    "    ents = ModeloNerUtilsObj.remove_labels(ents, PARAM[\"remover_labels\"])\n",
    "    ents = ModeloNerUtilsObj.merge_labels_from_to(ents, PARAM[\"merges\"])\n",
    "    return ents\n",
    "\n",
    "\n",
    "resposta_gerada = model_fun(TEXT_LOADED)\n",
    "resposta_gerada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_transformer_to_dict(ents):\n",
    "    result = {}\n",
    "    for ent in ents:\n",
    "        entity_group = ent[\"entity_group\"]\n",
    "        word = ent[\"word\"]\n",
    "        if entity_group not in result:\n",
    "            result[entity_group] = []\n",
    "        result[entity_group].append(word)\n",
    "        result[entity_group] = list(set(result[entity_group]))\n",
    "    return result\n",
    "\n",
    "\n",
    "# =========\n",
    "\n",
    "resp_model = convert_transformer_to_dict(model_fun(TEXT_LOADED))\n",
    "resp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_words_to_labels_ids(\n",
    "    TEXT_LOADED, dados=convert_transformer_to_dict(model_fun(TEXT_LOADED))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os Dados Fake Anotados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto_teste_1_sintetico = {\n",
    "#     \"texto\": \"Marinalva Bete Raz e Jorge Luiz reclama por indenização no valor de R$ 82.662,00 e da-costamarcos-vinicius@example.net e CEP 85123-123. Com endereço no Trevo Alves, 453, Carlos Prates, 27929672 Farias/AP, mesmo assim.\",\n",
    "#     \"dados_sinteticos\": {\n",
    "#         \"NOME\": [\"Marinalva Bete Raz\", \"Jorge Luiz\"],\n",
    "#         \"DINHEIRO\": [\"R$ 82.662,00\"],\n",
    "#         \"CEP\": [\"85123-123\"],\n",
    "#         \"EMAIL\": [\"da-costamarcos-vinicius@example.net\"],\n",
    "#         \"ENDERECO\": [\"Trevo Alves, 453\\\\nCarlos Prates\\\\n27929672 Farias / AP\"],\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # ======\n",
    "# print(\n",
    "#     convert_words_to_labels_ids(\n",
    "#         texto_teste_1_sintetico[\"texto\"],\n",
    "#         dados=texto_teste_1_sintetico[\"dados_sinteticos\"],\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodando a Avaliação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DADOS_AVALIACAO_GERADOS = []\n",
    "\n",
    "for item in DADOS_FAKE:\n",
    "    try:\n",
    "        from_model = convert_words_to_labels_ids(\n",
    "            item[\"texto\"], dados=convert_transformer_to_dict(model_fun(item[\"texto\"]))\n",
    "        )\n",
    "\n",
    "        DADOS_AVALIACAO_GERADOS.append(from_model)\n",
    "    except Exception as e:\n",
    "        print(\"Erro: \", e)\n",
    "        print(\"Texto: \", item)\n",
    "\n",
    "# ===========\n",
    "\n",
    "print(\"\\n\\nQnt DADOS_AVALIACAO_GERADOS: \", len(DADOS_AVALIACAO_GERADOS))\n",
    "# print(\"\\nDADOS_AVALIACAO_GERADOS: \", DADOS_AVALIACAO_GERADOS[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally DADOS_AVALIACAO_GERADOS and load after\n",
    "# import pickle\n",
    "\n",
    "# Save\n",
    "# with open(\"./output/DADOS_AVALIACAO_GERADOS.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(DADOS_AVALIACAO_GERADOS, f)\n",
    "\n",
    "# Load\n",
    "# with open(\"./output/DADOS_AVALIACAO_GERADOS.pkl\", \"rb\") as f:\n",
    "#     DADOS_AVALIACAO_GERADOS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DADOS_AVALIACAO_SINTETICOS = []\n",
    "\n",
    "for item in DADOS_FAKE:\n",
    "    # print(type(item[\"dados_sinteticos\"]), item[\"dados_sinteticos\"])\n",
    "    try:\n",
    "        from_sint = convert_words_to_labels_ids(\n",
    "            item[\"texto\"],\n",
    "            # dados=json.loads(item[\"dados_sinteticos_merged\"].replace(\"'\", '\"')),\n",
    "            dados=json.loads(item[\"dados_sinteticos\"].replace(\"'\", '\"')),\n",
    "        )\n",
    "\n",
    "        DADOS_AVALIACAO_SINTETICOS.append(from_sint)\n",
    "    except Exception as e:\n",
    "        print(\"Erro: \", e)\n",
    "        print(\"Texto: \", item)\n",
    "\n",
    "# ===========\n",
    "\n",
    "print(\"\\n\\nQnt DADOS_AVALIACAO_SINTETICOS: \", len(DADOS_AVALIACAO_SINTETICOS))\n",
    "# print(\"\\nDADOS_AVALIACAO_SINTETICOS: \", DADOS_AVALIACAO_SINTETICOS[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID2LABEL = {i: label for i, label in enumerate(LABELS)}\n",
    "ID2LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/spaces/evaluate-metric/seqeval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "def run_avaliacao(dados_sinteticos, dados_gerados, id2label={}):\n",
    "    metric = load_metric(\"seqeval\", trust_remote_code=True)\n",
    "\n",
    "    # Get predictions and references\n",
    "    predictions = [d[1] for d in dados_gerados]\n",
    "    references = [d[1] for d in dados_sinteticos]\n",
    "\n",
    "    # Checking if the lengths are the same\n",
    "    for ind, arr in enumerate(predictions):\n",
    "        size_predictions = len(predictions[ind])\n",
    "        size_references = len(references[ind])\n",
    "\n",
    "        if size_predictions != size_references:\n",
    "            print(\n",
    "                f\"Error Index {ind}: The number of predictions ({size_predictions}) is different from the number of references ({size_references})\"\n",
    "            )\n",
    "            # Adding more zeros to the end of the smallest list\n",
    "            if size_predictions < size_references:\n",
    "                for i in range(size_references - size_predictions):\n",
    "                    predictions[ind].append(0)\n",
    "            else:\n",
    "                for i in range(size_predictions - size_references):\n",
    "                    references[ind].append(0)\n",
    "\n",
    "    # Convert id to label\n",
    "    predictions_labels = []\n",
    "    for preds in predictions:\n",
    "        predictions_labels.append([id2label[pred] for pred in preds])\n",
    "\n",
    "    references_labels = []\n",
    "    for refs in references:\n",
    "        references_labels.append([id2label[ref] for ref in refs])\n",
    "\n",
    "    results = metric.compute(\n",
    "        predictions=predictions_labels, references=references_labels, zero_division=0\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "# ==========\n",
    "\n",
    "d_sin = [\n",
    "    [[\"texto\"], [1, 1, 1, 0, 3, 0, 6]],\n",
    "    [[\"texto\"], [1, 1, 0, 2, 2]],\n",
    "    [[\"texto\"], [1, 1, 0, 2, 2]],\n",
    "]\n",
    "d_ger = [\n",
    "    [[\"texto\"], [1, 1, 1, 0, 0, 0, 6]],\n",
    "    [[\"texto\"], [1, 1, 0, 0, 2]],\n",
    "    [[\"texto\"], [1, 1, 0, 2, 2, 0]],\n",
    "]\n",
    "\n",
    "run_avaliacao(d_sin, d_ger, ID2LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação F1 para o Artigo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = run_avaliacao(DADOS_AVALIACAO_SINTETICOS, DADOS_AVALIACAO_GERADOS, ID2LABEL)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_order = [\n",
    "    \"NOME\",\n",
    "    \"DATA\",\n",
    "    \"ENDERECO\",\n",
    "    \"CPF\",\n",
    "    \"TELEFONE\",\n",
    "    \"EMAIL\",\n",
    "    \"DINHEIRO\",\n",
    "    \"CEP\",\n",
    "]\n",
    "\n",
    "# Reorganizar o input_json de acordo com input_json_order\n",
    "input_json = resp\n",
    "input_json_new = {key: input_json[key] for key in input_json_order}\n",
    "\n",
    "# Adicionar as métricas \"overall\" ao final\n",
    "input_json_new[\"overall_precision\"] = input_json[\"overall_precision\"]\n",
    "input_json_new[\"overall_recall\"] = input_json[\"overall_recall\"]\n",
    "input_json_new[\"overall_f1\"] = input_json[\"overall_f1\"]\n",
    "input_json_new[\"overall_accuracy\"] = input_json[\"overall_accuracy\"]\n",
    "\n",
    "# input_json_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela Latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_tabela_latex_de_avaliacao(\n",
    "    input_json, titulo=\"Avaliação do novo Modelo NER\", round_num=2\n",
    "):\n",
    "    # Cabeçalho da tabela LaTeX\n",
    "    tabela_latex = (\n",
    "        \"\"\"\\\\begin{table}[H]\n",
    "    \\\\centering\n",
    "    \\\\caption{\"\"\"\n",
    "        + titulo\n",
    "        + \"\"\"}\n",
    "    \\\\label{tab:avaliacao_ner_com_correcoes}\n",
    "    \\\\begin{tabular}{|l|l|l|l|l|}\n",
    "    \\\\hline\n",
    "    \\\\textbf{Entity}  & \\\\textbf{Precision} & \\\\textbf{Recall} & \\\\textbf{F1-Score} & \\\\textbf{Support} \\\\\\\\\n",
    "    \\\\hline\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Adicionar linhas para cada entidade\n",
    "    for entity, metrics in input_json.items():\n",
    "        if entity.startswith(\"overall\"):\n",
    "            continue\n",
    "        precision = round(metrics[\"precision\"], round_num)\n",
    "        recall = round(metrics[\"recall\"], round_num)\n",
    "        f1 = round(metrics[\"f1\"], round_num)\n",
    "        support = metrics[\"number\"]\n",
    "        tabela_latex += f\"{entity} & {precision} & {recall} & {f1} & {support} \\\\\\\\\\n\"\n",
    "\n",
    "    tabela_latex += \"\\\\hline\\n\"\n",
    "\n",
    "    # Adicionar linha para Overall\n",
    "    overall_precision = round(input_json[\"overall_precision\"], round_num)\n",
    "    overall_recall = round(input_json[\"overall_recall\"], round_num)\n",
    "    overall_f1 = round(input_json[\"overall_f1\"], round_num)\n",
    "    tabela_latex += f\"\\\\textbf{{Overall}} & {overall_precision} & {overall_recall} & {overall_f1} & - \\\\\\\\\\n\"\n",
    "\n",
    "    tabela_latex += \"\"\"\\\\hline\n",
    "    \\\\end{tabular}\n",
    "    \\\\end{table}\"\"\"\n",
    "\n",
    "    return tabela_latex\n",
    "\n",
    "\n",
    "print(gerar_tabela_latex_de_avaliacao(input_json_new, round_num=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Dataset para Treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve DADOS_AVALIACAO_SINTETICOS com o pandas e em formato Parquet\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "\n",
    "\n",
    "df_sint = pd.DataFrame(DADOS_AVALIACAO_SINTETICOS, columns=[\"texto\", \"labels\"])\n",
    "df_sint.to_parquet(\"./output/DADOS_AVALIACAO_SINTETICOS.parquet\")\n",
    "df_sint.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos de Erro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DADOS_AVALIACAO_GERADOS[8:9][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     DADOS_AVALIACAO_GERADOS[8:9][0][\"inputs_ids\"],\n",
    "#     len(DADOS_AVALIACAO_GERADOS[8:9][0][\"inputs_ids\"]),\n",
    "\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_compare(\n",
    "    dados_sinteticos,\n",
    "    dados_gerados,\n",
    "    id2label={},\n",
    "    filter_by_labels=[],\n",
    "    original_data=None,\n",
    "    padding_show=5,\n",
    "):\n",
    "    # Get predictions and references\n",
    "    predictions = [d[1] for d in dados_gerados]\n",
    "    references = [d[1] for d in dados_sinteticos]\n",
    "\n",
    "    qnt_total = 0\n",
    "    # Showing the differences by labels\n",
    "    for i, (pred, ref) in enumerate(zip(predictions, references)):\n",
    "        if pred != ref:\n",
    "            is_first_time = True\n",
    "\n",
    "            for j, (p, r) in enumerate(zip(pred, ref)):\n",
    "                # show excerpt from the error with padding of 5 words\n",
    "\n",
    "                previsa_diff_from_ref = p != r\n",
    "                is_prev_has_in_filter = id2label[p][2:] in filter_by_labels\n",
    "                is_ref_has_in_filter = id2label[r][2:] in filter_by_labels\n",
    "                is_prev_or_ref_has_in_filter = (\n",
    "                    is_prev_has_in_filter or is_ref_has_in_filter\n",
    "                )\n",
    "\n",
    "                if previsa_diff_from_ref and is_prev_or_ref_has_in_filter:\n",
    "                    if previsa_diff_from_ref and is_first_time:\n",
    "                        print(\"\\n\")\n",
    "                        print(f\"============= Index {i} =============\")\n",
    "\n",
    "                        if original_data is None:\n",
    "                            print(f\"Texto: {' '.join(dados_sinteticos[i][0])}\")\n",
    "                        else:\n",
    "                            print(f\"Texto: {original_data[i]['texto']}\")\n",
    "                        is_first_time = False\n",
    "                        qnt_total += 1\n",
    "\n",
    "                    print(\"\\n\")\n",
    "                    print(f\"Pred -> Index {j} - Ref: {id2label[p]}\")\n",
    "                    print(f\"Ref -> Index {j} - Ref: {id2label[r]}\")\n",
    "                    print(\n",
    "                        f\"Text: {dados_sinteticos[i][0][j-padding_show:j+padding_show]}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"Text junto: {' '.join(dados_sinteticos[i][0][j-padding_show:j+padding_show])}\"\n",
    "                    )\n",
    "\n",
    "    if qnt_total > 0:\n",
    "        print(f\"\\n\\n ========= Quantidade Total: {qnt_total} =========\\n\\n\")\n",
    "\n",
    "\n",
    "# ==========\n",
    "\n",
    "\n",
    "d_sin = [\n",
    "    [\n",
    "        [\n",
    "            \"Marinalva\",\n",
    "            \"Bete\",\n",
    "            \"Raz\",\n",
    "            \"e\",\n",
    "            \"Jorge\",\n",
    "            \"Luiz\",\n",
    "            \"do\",\n",
    "            \"cpf\",\n",
    "            \"637\",\n",
    "            \".\",\n",
    "            \"841\",\n",
    "            \".\",\n",
    "            \"250\",\n",
    "            \"-\",\n",
    "            \"36\",\n",
    "            \".\",\n",
    "        ],\n",
    "        [1, 2, 2, 0, 1, 2, 0, 0, 7, 8, 8, 8, 8, 8, 8, 0],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            \"Marinalva\",\n",
    "            \"Bete\",\n",
    "            \"Raz\",\n",
    "            \"e\",\n",
    "            \"Jorge\",\n",
    "            \"Luiz\",\n",
    "            \"do\",\n",
    "            \"cpf\",\n",
    "            \"637\",\n",
    "            \".\",\n",
    "            \"841\",\n",
    "            \".\",\n",
    "            \"250\",\n",
    "            \"-\",\n",
    "            \"36\",\n",
    "            \".\",\n",
    "        ],\n",
    "        [1, 2, 2, 0, 1, 2, 0, 0, 7, 8, 8, 8, 8, 8, 8, 0],\n",
    "    ],\n",
    "]\n",
    "d_ger = [\n",
    "    [\n",
    "        [\n",
    "            \"Marinalva\",\n",
    "            \"Bete\",\n",
    "            \"Raz\",\n",
    "            \"e\",\n",
    "            \"Jorge\",\n",
    "            \"Luiz\",\n",
    "            \"do\",\n",
    "            \"cpf\",\n",
    "            \"637\",\n",
    "            \".\",\n",
    "            \"841\",\n",
    "            \".\",\n",
    "            \"250\",\n",
    "            \"-\",\n",
    "            \"36\",\n",
    "            \".\",\n",
    "        ],\n",
    "        [1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            \"Marinalva\",\n",
    "            \"Bete\",\n",
    "            \"Raz\",\n",
    "            \"e\",\n",
    "            \"Jorge\",\n",
    "            \"Luiz\",\n",
    "            \"do\",\n",
    "            \"cpf\",\n",
    "            \"637\",\n",
    "            \".\",\n",
    "            \"841\",\n",
    "            \".\",\n",
    "            \"250\",\n",
    "            \"-\",\n",
    "            \"36\",\n",
    "            \".\",\n",
    "        ],\n",
    "        [1, 2, 2, 0, 1, 2, 5, 0, 7, 8, 8, 8, 8, 8, 8, 0],\n",
    "    ],\n",
    "]\n",
    "\n",
    "run_compare(d_sin, d_ger, ID2LABEL, filter_by_labels=[\"CPF\", \"ENDERECO\"])\n",
    "# run_compare(d_sin, d_ger, ID2LABEL, filter_by_labels=[\"ENDERECO\"])\n",
    "# run_compare(\n",
    "#     d_sin,\n",
    "#     d_ger,\n",
    "#     ID2LABEL,\n",
    "#     filter_by_labels=[\"CPF\", \"ENDERECO\"],\n",
    "#     original_data=DADOS_FAKE,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando os erros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_comp = run_compare(\n",
    "    DADOS_AVALIACAO_SINTETICOS,\n",
    "    DADOS_AVALIACAO_GERADOS,\n",
    "    ID2LABEL,\n",
    "    filter_by_labels=[\"CPF\"],\n",
    "    original_data=DADOS_FAKE,\n",
    "    padding_show=1,\n",
    ")\n",
    "resp_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dados_sinteticos_from_index(dados=DADOS_FAKE, index=0):\n",
    "    dados_ind = dados[index]\n",
    "    texto = dados_ind[\"texto\"]\n",
    "\n",
    "    dados_sint_ind_prev = convert_transformer_to_dict(model_fun(texto))\n",
    "    dados_sint_ind_ref = json.loads(dados_ind[\"dados_sinteticos\"].replace(\"'\", '\"'))\n",
    "    # dados_sint_ind_ref = json.loads(\n",
    "    #     dados_ind[\"dados_sinteticos_merged\"].replace(\"'\", '\"')\n",
    "    # )\n",
    "\n",
    "    return texto, dados_sint_ind_ref, dados_sint_ind_prev\n",
    "\n",
    "\n",
    "# ===============\n",
    "get_dados_sinteticos_from_index(index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dados_sinteticos_from_index(index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dados_sinteticos_from_index(index=601)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TELEFONE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_comp = run_compare(\n",
    "    DADOS_AVALIACAO_SINTETICOS,\n",
    "    DADOS_AVALIACAO_GERADOS,\n",
    "    ID2LABEL,\n",
    "    filter_by_labels=[\"TELEFONE\"],\n",
    "    original_data=DADOS_FAKE,\n",
    "    padding_show=1,\n",
    ")\n",
    "resp_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dados_sinteticos_from_index(index=139)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp_comp = run_compare(\n",
    "#     DADOS_AVALIACAO_SINTETICOS,\n",
    "#     DADOS_AVALIACAO_GERADOS,\n",
    "#     ID2LABEL,\n",
    "#     filter_by_labels=[\"CEP\"],\n",
    "#     original_data=DADOS_FAKE,\n",
    "#     padding_show=1,\n",
    "# )\n",
    "# resp_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dados_sinteticos_from_index(index=235)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENDERECO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_comp = run_compare(\n",
    "    DADOS_AVALIACAO_SINTETICOS,\n",
    "    DADOS_AVALIACAO_GERADOS,\n",
    "    ID2LABEL,\n",
    "    filter_by_labels=[\"ENDERECO\"],\n",
    "    original_data=DADOS_FAKE,\n",
    "    padding_show=1,\n",
    ")\n",
    "resp_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dados_sinteticos_from_index(index=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dados_sinteticos_from_index(index=72)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
